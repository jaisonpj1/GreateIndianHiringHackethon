{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Basic Dependencies\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read training Data\ndf_train = pd.read_csv(\"/kaggle/input/retailcleanfull/Train_clean.csv\")\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read testing data\ndf_test = pd.read_csv(\"/kaggle/input/retailcleanfull/Test_clean.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Column Types\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy.random import seed\nfrom numpy.random import randn\nfrom numpy import percentile\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndf = df['Quantity']\n# calculate interquartile range\nq25, q75 = percentile(df, 25), percentile(df, 75)\niqr = q75 - q25\nprint('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n# calculate the outlier cutoff\ncut_off = iqr * 1.5\nlower, upper = q25 - cut_off, q75 + cut_off\n# identify outliers\noutliers = [x for x in df if x < lower or x > upper]\nprint('Identified outliers: %d' % len(outliers))\n# remove outliers\noutliers_removed = [x for x in df if x >= lower and x <= upper]\nprint('Non-outlier observations: %d' % len(outliers_removed))\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Basic Stats\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for Missing Values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seperate Categorical and Numerical Columns\ncat_cols = data.select_dtypes(include=['object','category']).columns.tolist()\nprint(cat_cols)\n\nnum_cols = data.select_dtypes(include=['int64','float64']).columns.tolist()\nprint(num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: data[col].nunique(), cat_cols))\nd = dict(zip(cat_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop irrelavent columns\n\ndata1 = data.drop(['AM/PM_PM_sin','AM/PM_PM_cos','InvoiceNo','CustomerID','Time_sin','Time_cos','Year_cos'],1, inplace= False)\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['UnitPrice']:\n    min_thresold, max_thresold = data1[col].quantile([0.001, 0.999])\n    min_thresold, max_thresold\n\n    #data = data[(data.UnitPrice<35) & (data1.UnitPrice>0)]\n    data1 = data1[(data1[col]<max_thresold) & (data1[col]>min_thresold)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for skewness in the dataset\ndata1.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.UnitPrice.hist(bins = 25)\nprint()\ndata1.UnitPrice.skew()\n#Highly skewed scaling needs to done before applying any regression model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data1.corr(method='pearson')\ncorr_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#corrleation with area\ncorr_matrix.UnitPrice.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take targate variable into y\ny = data1['UnitPrice']\nX = data1.drop('UnitPrice',axis = 1)\n\nfrom sklearn.preprocessing import PowerTransformer\ny = y.values.reshape(-1,1)\n# power transform the raw data\npower = PowerTransformer(method='yeo-johnson', standardize=True)\ny = power.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into train and test format\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\npipelines = []\npipelines.append(('ScaledLR', Pipeline([('Scaler', MinMaxScaler()),('LR',LinearRegression())])))\npipelines.append(('ScaledLASSO', Pipeline([('Scaler', MinMaxScaler()),('LASSO', Lasso())])))\n#pipelines.append(('ScaledEN', Pipeline([('Scaler', MinMaxScaler()),('EN', ElasticNet())])))\npipelines.append(('ScaledDT', Pipeline([('Scaler', MinMaxScaler()),('DT', DecisionTreeRegressor())])))\npipelines.append(('ScaledRF', Pipeline([('Scaler', MinMaxScaler()),('RF', RandomForestRegressor())])))\npipelines.append(('ScaledET', Pipeline([('Scaler', MinMaxScaler()),('ET', ExtraTreesRegressor())])))\npipelines.append(('ScaledGBM', Pipeline([('Scaler', MinMaxScaler()),('GBM', GradientBoostingRegressor())])))\npipelines.append(('ScaledXGB', Pipeline([('Scaler', MinMaxScaler()),('XGB', XGBRegressor())])))\n#pipelines.append(('ScaledNN', Pipeline([('Scaler', MinMaxScaler()),('NN', MLPRegressor())])))\n#pipelines.append(('ScaledSVR', Pipeline([('Scaler', MinMaxScaler()),('SVR', SVR(kernel='rbf'))])))\n#pipelines.append(('ScaledKNN', Pipeline([('Scaler', MinMaxScaler()),('KNN', KNeighborsRegressor())])))\n\nresults = []\nnames = []\nfor name, model in pipelines:\n    kfold = KFold(n_splits=10, random_state=10)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error',n_jobs=-1)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ScaledLR: -0.987738 (0.006656)\nScaledLASSO: -0.999019 (0.005722)\nScaledEN: -0.999019 (0.005722)\nScaledDT: -0.056389 (0.003337)\nScaledRF: -0.032720 (0.001946)\nScaledET: -0.015866 (0.000895)\nScaledGBM: -0.526374 (0.006337)\nScaledXGB: -0.120653 (0.002417","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ScaledET is best performing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nET_model = ExtraTreesRegressor()\n# evaluate the model\ncv = RepeatedKFold(n_splits=25, n_repeats=25, random_state=2)\nn_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise',verbose=1)\n# report performance\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ET_model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_max = max(n_scores)\nprint( \"At K = {}, Max Accuracy = {}\".format(k_max, max(n_scores)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\npredictions = ET_model.predict(X_test)\nMSE = mean_squared_error(y_test , predictions)\nprint('ExtraTrees validation MAE = ',MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ExtraTrees validation MAE =  0.00018089177342840292","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decition Tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n# define the model\nDT_model = DecisionTreeRegressor()\n# evaluate the model\ncv = RepeatedKFold(n_splits=30, n_repeats=10, random_state=21)\nn_scores = cross_val_score(DT_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise',verbose=1)\n# report performance\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\npredictions = DT_model.predict(X_test)\nMSE = mean_squared_error(y_test , predictions)\nprint('ExtraTrees validation MAE = ',MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n# define the model\nRF_model = RandomForestRegressor()\n# evaluate the model\ncv = RepeatedKFold(n_splits=50, n_repeats=50, random_state=50)\nn_scores = cross_val_score(RF_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise',verbose=1)\n# report performance\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\npredictions = RF_model.predict(X_test)\nMSE = mean_squared_error(y_test , predictions)\nprint('ExtraTrees validation MAE = ',MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n# define the model\nXGB_model = XGBRegressor()\n# evaluate the model\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nn_scores = cross_val_score(XGB_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise',verbose=1)\n# report performance\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\npredictions = XGB_model.predict(X_test)\nMSE = mean_squared_error(y_test , predictions)\nprint('ExtraTrees validation MAE = ',MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Using K_Nearest neighbour regressor\n# running for different K values to know which yields the max accuracy.\nfrom sklearn.neighbors import KNeighborsRegressor\nscore = []\nfor k in range(1,20):    \n    clf = KNeighborsRegressor(n_neighbors = k,  weights = 'distance', p=1)\n    clf.fit(X_train, y_train)\n    score.append(clf.score(X_test, y_test))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"k_max = score.index(max(score))+1\nprint( \"At K = {}, Max Accuracy = {}\".format(k_max, max(score)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = KNeighborsRegressor(n_neighbors = k_max,  weights = 'distance', p=1)\nclf.fit(X_train, y_train)\nprint(clf.score(X_test, y_test ))   \ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import joblib\n# save the model to disk\nfilename = 'KNN_Regressor_MachineHack.sav'\njoblib.dump(model, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read testing data\ndf_test = pd.read_csv(\"/kaggle/input/retailcleanfull/Test_clean.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = df_test.drop(['AM/PM_PM_sin','AM/PM_PM_cos','InvoiceNo','CustomerID','Time_sin','Time_cos','Year_cos'],1, inplace= False)\ndata_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply the whole pipeline to data\nresults = DT_model.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(data=results)\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying inverse power transform to get back original form of unit price\na_inverse_transformed = power.inverse_transform(result)\na_inverse_transformed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(data=a_inverse_transformed).round(2)\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=result.rename(columns={0:'UnitPrice'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv(\"my_submission_file.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}